# frozen_string_literal: true

require 'open-uri'
require 'tty-prompt'
require_relative 'comprehensive_scan'
require_relative 'web_application_exploitation_ascii_art'

# This class display the menu and houses the funtions for the robots.txt scan
# The website scan scans a website for its robots.txt page
class RobotsScan < ComprehensiveScan
  def initialize(comprehensive = false, *url)
    @url = url if comprehensive == true

    WebApplicationExploitationAsciiArt.new('robots')
    @url = obtain_url
    select_robots_mode
  end

  def select_robots_mode
    prompt = TTY::Prompt.new

    choices = [
      { name: 'Scan for robots.txt', value: lambda {
        WebApplicationExploitationAsciiArt.new('robots') && fetch_robots_txt
      } },
      { name: 'Go to previosu menu', value: -> { WebApplicationExploitation.new } },
      { name: 'Go to Main Menu', value: -> { Toolbox.new } },
      { name: 'Quit application', value: -> { clear_terminal && quit } }
    ]

    prompt.select('Please select your mode', choices, per_page: 4, cycle: true)
  end

  def fetch_robots_txt
    robots_url = URI.join(@url, '/robots.txt').to_s
    begin
      # obtain_url, the function that gives the url, sanitizes the input
      robots_content = URI.open(robots_url).read # rubocop:disable Security/Open
      puts "Contents of robots.txt for #{@url}:"
      print_disallow_lines(robots_content)
      quit_or_continue(RobotsScan)
    rescue OpenURI::HTTPError => e
      puts "Failed to fetch robots.txt: #{e.message}"
      quit_or_continue(RobotsScan)
    end
  end

  def print_disallow_lines(robots_content)
    robots_content.each_line do |line|
      if line.strip.start_with?('Disallow')
        puts line.strip.colorize(:green)
      else
        puts line.strip
      end
    end
  end
end
